{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2fe9a54",
      "metadata": {},
      "source": [
        "# Saliency Map Demo\n",
        "\n",
        "This demo is divided into two parts -- model training and . The first is a\n",
        "slightly simplified example from the `torchgeo` documentation, originally\n",
        "written by Caleb Robinson, which fine-tunes a land cover classifier using a\n",
        "ResNet classifier pretrained on a large satellite imagery dataset. The second\n",
        "shows how we can use the captum package to compute gradient and integrated\n",
        "gradient-based saliency maps to explain individual predictions, with an eye\n",
        "especially towards the model's mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ee9a88",
      "metadata": {},
      "source": [
        "To run this notebook yourself, you can setup a new conda environment with the packages installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2fc78a",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# select \"stat992_week2\" as your notebook kernel\n",
        "!conda env create -f https://github.com/krisrs1128/stat992_s25/raw/refs/heads/main/demos/stat992_week2.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8c2372",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e563313d",
      "metadata": {
        "id": "e563313d"
      },
      "source": [
        "_Written by: Caleb Robinson_\n",
        "\n",
        "In this tutorial, we demonstrate TorchGeo trainers to train and test a model. We will use the [EuroSAT](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#eurosat) dataset throughout this tutorial. Specifically, a subset containing only 100 images. We will train models to predict land cover classes.\n",
        "\n",
        "It's recommended to run this notebook on Google Colab if you don't have your own GPU. Click the \"Open in Colab\" button above to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd39f485",
      "metadata": {
        "id": "bd39f485"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "\n",
        "import torch\n",
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "from torchgeo.datamodules import EuroSAT100DataModule\n",
        "from torchgeo.models import ResNet18_Weights\n",
        "from torchgeo.trainers import ClassificationTask\n",
        "from captum.attr import Saliency, IntegratedGradients\n",
        "from captum.attr import visualization as viz\n",
        "torch.manual_seed(20250130)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e1d9b6",
      "metadata": {
        "id": "e6e1d9b6"
      },
      "source": [
        "## Lightning modules\n",
        "\n",
        "Our trainers use [Lightning](https://lightning.ai/docs/pytorch/stable/) to organize both the training code, and the dataloader setup code. This makes it easy to create and share reproducible experiments and results.\n",
        "\n",
        "First we'll create a `EuroSAT100DataModule` object which is simply a wrapper around the [EuroSAT100](https://torchgeo.readthedocs.io/en/latest/api/datasets.html#eurosat) dataset. This object 1.) ensures that the data is downloaded, 2.) sets up PyTorch `DataLoader` objects for the train, validation, and test splits, and 3.) ensures that data from the same region **is not** shared between the training and validation sets so that you can properly evaluate the generalization performance of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f2daa0d",
      "metadata": {
        "id": "9f2daa0d"
      },
      "source": [
        "The following variables can be modified to control training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e100f8b",
      "metadata": {
        "id": "8e100f8b",
        "nbmake": {
          "mock": {
            "batch_size": 1,
            "fast_dev_run": true,
            "max_epochs": 1,
            "num_workers": 0
          }
        }
      },
      "outputs": [],
      "source": [
        "batch_size = 25\n",
        "num_workers = 2\n",
        "max_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0f2a04c7",
      "metadata": {
        "id": "0f2a04c7"
      },
      "outputs": [],
      "source": [
        "datamodule = EuroSAT100DataModule(root='.', batch_size=batch_size, num_workers=num_workers, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056b7b4c",
      "metadata": {
        "id": "056b7b4c"
      },
      "source": [
        "Next, we create a `ClassificationTask` object that holds the model object, optimizer object, and training logic. We will use a ResNet-18 model that has been pre-trained on Sentinel-2 imagery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba5c5442",
      "metadata": {
        "id": "ba5c5442"
      },
      "outputs": [],
      "source": [
        "task = ClassificationTask(\n",
        "    loss='ce',\n",
        "    model='resnet18',\n",
        "    weights=ResNet18_Weights.SENTINEL2_ALL_MOCO,\n",
        "    in_channels=13,\n",
        "    num_classes=10,\n",
        "    lr=0.05,\n",
        "    patience=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b67f3e",
      "metadata": {
        "id": "d4b67f3e"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have the Lightning modules set up, we can use a Lightning [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) to run the training and evaluation loops. There are many useful pieces of configuration that can be set in the `Trainer` -- below we set up model checkpointing based on the validation loss, early stopping based on the validation loss, and a TensorBoard based logger. We encourage you to see the [Lightning docs](https://lightning.ai/docs/pytorch/stable/) for other options that can be set here, e.g. CSV logging, automatically selecting your optimizer's learning rate, and easy multi-GPU training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ffe26e5c",
      "metadata": {
        "id": "ffe26e5c"
      },
      "outputs": [],
      "source": [
        "accelerator = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "logger = TensorBoardLogger(save_dir='.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06afd8c7",
      "metadata": {
        "id": "06afd8c7"
      },
      "source": [
        "For tutorial purposes we deliberately lower the maximum number of training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225a6d36",
      "metadata": {
        "id": "225a6d36"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    accelerator=accelerator,\n",
        "    log_every_n_steps=1,\n",
        "    logger=logger,\n",
        "    min_epochs=1,\n",
        "    max_epochs=max_epochs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d71e8f",
      "metadata": {
        "id": "44d71e8f"
      },
      "source": [
        "When we first call `.fit(...)` the dataset will be downloaded and checksummed (if it hasn't already). After this, the training process will kick off, and results will be saved so that TensorBoard can read them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e08790",
      "metadata": {
        "id": "00e08790"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model=task, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73700fb5",
      "metadata": {
        "id": "73700fb5"
      },
      "source": [
        "We launch TensorBoard to visualize various performance metrics across training and validation epochs. We can see that our model is just starting to converge, and would probably benefit from additional training time and a lower initial learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e95ee0a",
      "metadata": {
        "id": "3e95ee0a"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04cfc7a8",
      "metadata": {
        "id": "04cfc7a8"
      },
      "source": [
        "## Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7dd4788",
      "metadata": {},
      "source": [
        "First, let's extract a batch of examples and compute predictions on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa8d98bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_iter = iter(datamodule.train_dataloader())\n",
        "batch = next(data_iter)\n",
        "\n",
        "images = batch[\"image\"]\n",
        "labels = batch[\"label\"]\n",
        "predicted = task(batch[\"image\"]).argmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b85ab75",
      "metadata": {},
      "source": [
        "Let's now visualize all the predictions for this batch along with the ground truth class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "604a3b2f",
      "metadata": {
        "id": "604a3b2f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_ = [\"Annual Crop\", \"Forest\", \"Herbaceous Vegetation\", \"Highway\",\n",
        "          \"Industrial Buildings\", \"Pasture\", \"Permanent Crop\", \n",
        "          \"Residential Buildings\", \"River\", \"Sea & Lake\"]\n",
        "\n",
        "for index in range(batch_size):\n",
        "    input_image = images[index].unsqueeze(0)\n",
        "    x = input_image.detach().numpy()[0, [3,2,1]]\n",
        "\n",
        "    # plot the model's prediction\n",
        "    plt.imshow(np.transpose(x, (1, 2, 0))/ x.max())\n",
        "    plt.show()\n",
        "    output = task(input_image)\n",
        "\n",
        "    print(index)\n",
        "    print(\"Predicted: \", label_[predicted[index]])\n",
        "    print(\"True: \", label_[labels[index]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d98bc1",
      "metadata": {},
      "source": [
        "Some of the mistakes seem to occur on ambiguous regions, where parts of the image seem to correspond to one class while other parts correspond to a different one. We can try to gauge this hypothesis by using different types of saliency maps. The results are not definitive. For both saliency maps and integrated gradients, the model seems to attend to parts of the image from both the correct class and the distracting background. Our hypothesis might be part of the story, but it doesn't seem to be the complete one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02aabe33",
      "metadata": {},
      "outputs": [],
      "source": [
        "index = 3\n",
        "input_image = batch[\"image\"][index].unsqueeze(0)\n",
        "x = input_image.detach().numpy()[0, [3,2,1]]\n",
        "x = np.transpose(x, (1, 2, 0))\n",
        "\n",
        "# initialize a Saliency object\n",
        "saliency = Saliency(task.model)\n",
        "z = saliency.attribute(input_image, target=predicted[index])\n",
        "\n",
        "# postprocess and visualize\n",
        "z = z.detach().numpy()[0]\n",
        "z = np.transpose(z, (1, 2, 0))\n",
        "_ = viz.visualize_image_attr(z, x, method = \"blended_heat_map\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79de703",
      "metadata": {},
      "outputs": [],
      "source": [
        "ig =  # ?\n",
        "\n",
        "# postprocess the integrated gradients\n",
        "#z = z.detach().numpy()[0]\n",
        "#z = np.transpose(z, (1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93e7802",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "execution": {
      "timeout": 1200
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "stat992_week2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
