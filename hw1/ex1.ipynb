{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution for recommender system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "!wget -q {url} -O ml-1m.zip\n",
    "!unzip -q ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ml-1m/ratings.dat\"\n",
    "movies_path = \"ml-1m/movies.dat\"\n",
    "users_path = \"ml-1m/users.dat\"\n",
    "\n",
    "data = pd.read_csv(data_path, sep=\"::\", names=[\"user\", \"item\", \"rating\", \"timestamp\"], engine=\"python\")\n",
    "movies = pd.read_csv(movies_path, sep=\"::\", names=[\"item\", \"title\", \"genres\"], engine=\"python\", encoding=\"ISO-8859-1\")\n",
    "users = pd.read_csv(users_path, sep=\"::\", names=[\"user\", \"gender\", \"age\", \"occupation\", \"zip\"], engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex\n",
    "user_mapping = {old:new for new, old in enumerate(users[\"user\"].unique())}\n",
    "item_mapping = {old:new for new, old in enumerate(movies[\"item\"].unique())}\n",
    "data[\"user\"] = data[\"user\"].map(user_mapping)\n",
    "data[\"item\"] = data[\"item\"].map(item_mapping)\n",
    "movies[\"item\"] = movies[\"item\"].map(item_mapping)\n",
    "users[\"user\"] = users[\"user\"].map(user_mapping)\n",
    "\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 3., ..., 5., 4., 4.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/8hzvmhln5p36t4tdqc9c52z40000gn/T/ipykernel_17204/1830612108.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    }
   ],
   "source": [
    "# define adjacency matrix\n",
    "def build_adj_matrix(data, num_users, num_items):\n",
    "    rows, cols = data['user'].values, data['item'].values\n",
    "    interactions = data['rating'].values.astype(np.float32)\n",
    "    adj_matrix = sp.coo_matrix((interactions, (rows, cols + num_users)), \n",
    "                               shape=(num_users+num_items, num_users+num_items))\n",
    "    adj_matrix = adj_matrix + adj_matrix.T # make the graph undirected\n",
    "    return adj_matrix\n",
    "\n",
    "adj_matrix = build_adj_matrix(data=data, num_users=num_users, num_items=num_items)\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return d_mat_inv_sqrt @ adj @ d_mat_inv_sqrt\n",
    "\n",
    "adj_matrix = normalize_adj(adj_matrix)\n",
    "adj_matrix = torch.FloatTensor(adj_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle user features\n",
    "gender_map = {'M':0, 'F':1}\n",
    "users['gender'] = users['gender'].map(gender_map)\n",
    "user_features = torch.FloatTensor(users[['gender', 'age', 'occupation']].values)\n",
    "\n",
    "# Handle item features  \n",
    "genres_set = set('|'.join(movies['genres']).split('|'))\n",
    "genre_mapping = {genre: i for i, genre in enumerate(genres_set)}\n",
    "movies['genres_encoded'] = movies['genres'].apply(lambda x: [genre_mapping[g] for g in x.split('|')])\n",
    "movie_features = torch.zeros((num_items, len(genres_set)))\n",
    "for i, row in movies.iterrows():\n",
    "    for g in row['genres_encoded']:\n",
    "        movie_features[row['item'], g] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, n_layers, user_feat_dim, item_feat_dim):\n",
    "        super(LightGCN, self).__init__()\n",
    "        # define user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        # project user and item features to embedding space\n",
    "        self.user_feat_fc = nn.Linear(user_feat_dim, embedding_dim) \n",
    "        self.item_feat_fc = nn.Linear(item_feat_dim, embedding_dim)\n",
    "        self.n_layers = n_layers\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "\n",
    "    def forward(self, adj, user_features, item_features):\n",
    "        user_feat_embed = self.user_feat_fc(user_features)\n",
    "        item_feat_embed = self.item_feat_fc(item_features)\n",
    "        all_embeddings = torch.cat([self.user_embedding.weight + user_feat_embed, self.item_embedding.weight + item_feat_embed], dim=0)\n",
    "        embeddings = [all_embeddings]\n",
    "        \n",
    "        for _ in range(self.n_layers):\n",
    "            all_embeddings = torch.mm(adj, all_embeddings)\n",
    "            embeddings.append(all_embeddings)\n",
    "        \n",
    "        final_embedding = torch.mean(torch.stack(embeddings, dim=0), dim=0)\n",
    "        user_final, item_final = torch.split(final_embedding, [num_users, num_items])\n",
    "        return user_final, item_final\n",
    "\n",
    "model = LightGCN(num_users, num_items, embedding_dim=64, n_layers=3, user_feat_dim=3, item_feat_dim=len(genres_set))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, data, adj, user_features, item_features, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        user_embed, item_embed = model(adj, user_features, item_features)\n",
    "        loss = 0\n",
    "        for user, item, rating in zip(data['user'], data['item'], data['rating']):\n",
    "            user_vec = user_embed[user]\n",
    "            item_vec = item_embed[item]\n",
    "            score = torch.sum(user_vec * item_vec)\n",
    "            loss += criterion(score, torch.tensor(float(rating)))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "train(model, data, adj_matrix, user_features, movie_features, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
